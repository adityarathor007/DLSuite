{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high dimension ranging is done so that both the foreground and the background is properly exposed\n",
    "# an hdr captures multiple images at different exposure and then merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def readImageAndTimes():\n",
    "    # List of file names\n",
    "    filenames=[\"img_0.033.jpg\",\"img_0.25.jpg\",\"img_2.5.jpg\",\"img_15.jpg\"]\n",
    "\n",
    "    # List of exposure times\n",
    "    times=np.array([1/30.0,0.25,2.5,15.0],dtype=np.float32)\n",
    "\n",
    "    # Read images\n",
    "    images=[]\n",
    "    for filename in filenames:\n",
    "        im=cv2.imread(filename)\n",
    "        im=cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "        images.append(im)\n",
    "\n",
    "    return images,times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 Align Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images and exposure times\n",
    "images,times=readImageAndTimes()\n",
    "\n",
    "# Align Image\n",
    "alignMTB=cv2.createAlignMTB()\n",
    "alignMTB.process(images,images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 Estimate Camera Response function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "needed because if the radiance is doubles then the pixel intensity recorded by the camera will not neccesarily double\n",
    "if the response function was linear then the intensities of the input images could be scaled by the exposure times which would put them on the same radian scale and then we could simply compute the average intensity at every pixel location across those images to synthesize an HDR image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the given images we compute this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find Camera Response Function (CRF)\n",
    "calibrateDebvec=cv2.createCalibrateDebevec()\n",
    "responseDebvec=calibrateDebvec.process(images,times)\n",
    "\n",
    "\n",
    "# Plot CRF\n",
    "x=np.arange(256,dtype=np.uint8)\n",
    "y=np.squeeze(responseDebvec)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
