{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.nn.functional import relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, a custom class UNet is defined as a subclass of nn.Module. \n",
    "# The __init__ method initializes the architecture of the U-Net by defining the layers for both the encoder and decoder parts of the network. \n",
    "# The argument n_class specifies the number of classes for the segmentation task.\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        # In the encoder, convolutional layers with the Conv2d function are used to extract features from the input image\n",
    "        # Each block in the encoder consists of 2 convlutional layer followed by a max polling layer, with the exception of last layer that does not include a max polling layer\n",
    "\n",
    "        # --- \n",
    "        # input: 572*572*3\n",
    "        self.e11=nn.Conv2d(3,64,kernel_size=3,padding=1) #output: 572*572*64\n",
    "        self.e12=nn.Conv2d(64,64,kernel_size=3,padding=1) #output: 572*572*64\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2,stride=2) #output: 284*284*64\n",
    "\n",
    "\n",
    "        # input: 284x284x64\n",
    "        self.e21 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # output: 284x284x128\n",
    "        self.e22 = nn.Conv2d(128, 128, kernel_size=3, padding=1) # output: 284x284x128\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 140x140x128\n",
    "\n",
    "\n",
    "         # input: 140x140x128\n",
    "        self.e31 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # output: 140x140x256\n",
    "        self.e32 = nn.Conv2d(256, 256, kernel_size=3, padding=1) # output: 140x140x256\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 68x68x256\n",
    "\n",
    "        # input: 68x68x256\n",
    "        self.e41 = nn.Conv2d(256, 512, kernel_size=3, padding=1) # output: 68x68x512\n",
    "        self.e42 = nn.Conv2d(512, 512, kernel_size=3, padding=1) # output: 68x68x512\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 32x32x512\n",
    "\n",
    "\n",
    "        # input: 32*32*512\n",
    "        self.e51=nn.Conv2d(512,1024,kernel_size=3,padding=1) #32*32*1024\n",
    "        self.e52=nn.Conv2d(1024,1024,kernel_size=3,padding=1) #32*32*1024\n",
    "\n",
    "\n",
    "        #Decoder \n",
    "        self.upconv1=nn.ConvTranspose2d(1024,512,kernel_size=2,stride=2) \n",
    "        self.d11=nn.Conv2d(1024,512,kernel_size=3,padding=1)\n",
    "        self.d12=nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
    "\n",
    "\n",
    "        self.upconv2=nn.ConvTranspose2d(512,256,kernel_size=2,stride=2) \n",
    "        self.d21=nn.Conv2d(512,256,kernel_size=3,padding=1)\n",
    "        self.d22=nn.Conv2d(256,256,kernel_size=3,padding=1)\n",
    "\n",
    "        self.upconv3=nn.ConvTranspose2d(256,128,kernel_size=2,stride=2) \n",
    "        self.d31=nn.Conv2d(256,128,kernel_size=3,padding=1)\n",
    "        self.d32=nn.Conv2d(128,128,kernel_size=3,padding=1)\n",
    "\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.d41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.d42 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "\n",
    "        # output_layer\n",
    "        self.outconv=nn.Conv2d(64,n_classes,kernel_size=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        xe11 = relu(self.e11(x))\n",
    "        xe12 = relu(self.e12(xe11))\n",
    "        xp1 = self.pool1(xe12)\n",
    "\n",
    "        xe21 = relu(self.e21(xp1))\n",
    "        xe22 = relu(self.e22(xe21))\n",
    "        xp2 = self.pool2(xe22)\n",
    "\n",
    "        xe31 = relu(self.e31(xp2))\n",
    "        xe32 = relu(self.e32(xe31))\n",
    "        xp3 = self.pool3(xe32)\n",
    "\n",
    "        xe41 = relu(self.e41(xp3))\n",
    "        xe42 = relu(self.e42(xe41))\n",
    "        xp4 = self.pool4(xe42)\n",
    "\n",
    "        xe51 = relu(self.e51(xp4))\n",
    "        xe52 = relu(self.e52(xe51))\n",
    "        \n",
    "\n",
    "          # Decoder\n",
    "        xu1 = self.upconv1(xe52)\n",
    "        xu11 = torch.cat([xu1, xe42], dim=1)\n",
    "        xd11 = relu(self.d11(xu11))\n",
    "        xd12 = relu(self.d12(xd11))\n",
    "\n",
    "        xu2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xu2, xe32], dim=1)\n",
    "        xd21 = relu(self.d21(xu22))\n",
    "        xd22 = relu(self.d22(xd21))\n",
    "\n",
    "        xu3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xu3, xe22], dim=1)\n",
    "        xd31 = relu(self.d31(xu33))\n",
    "        xd32 = relu(self.d32(xd31))\n",
    "\n",
    "        xu4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xu4, xe12], dim=1)\n",
    "        xd41 = relu(self.d41(xu44))\n",
    "        xd42 = relu(self.d42(xd41))\n",
    "\n",
    "\n",
    "        # Output layer\n",
    "        out = self.outconv(xd42)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from functools import reduce\n",
    "import itertools\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data(height,width,count):\n",
    "    X,y=zip(*[generate_img_and_mask(height,width) for i in range(0,count)])\n",
    "\n",
    "    X=np.asarray(X)*255\n",
    "    X = X.repeat(3, axis=1).transpose([0, 2, 3, 1]).astype(np.uint8)  #to convert from grayscale to rgb and then channel-first dimension to channel_last dimension and changing datatype to uint8\n",
    "\n",
    "\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def generate_img_and_mask(height,width):\n",
    "    shape=(height,width)\n",
    "\n",
    "    traingle_location=get_random_location(*shape)\n",
    "    circle_location1 = get_random_location(*shape, zoom=0.7)\n",
    "    circle_location2 = get_random_location(*shape, zoom=0.5)\n",
    "    mesh_location = get_random_location(*shape)\n",
    "    square_location = get_random_location(*shape, zoom=0.8)\n",
    "    plus_location = get_random_location(*shape, zoom=1.2)\n",
    "\n",
    "    arr=np.zeros(shape,dtype=bool)\n",
    "    arr=add_triangle(arr,*traingle_location)\n",
    "    arr=add_circle(arr,* circle_location1)\n",
    "    arr=add_circle(arr,*circle_location2)\n",
    "    arr=add_mesh_square(arr,*mesh_location)\n",
    "    arr=add_filled_square(arr,*square_location)\n",
    "    arr=add_plus(arr,*plus_location)\n",
    "\n",
    "    arr=np.reshape(arr,(1,height,width)).astype(np.float32)\n",
    "\n",
    "    masks = np.asarray([\n",
    "        add_filled_square(np.zeros(shape, dtype=bool), *square_location),\n",
    "        add_circle(np.zeros(shape, dtype=bool), *circle_location2, fill=True),\n",
    "        add_triangle(np.zeros(shape, dtype=bool), *traingle_location),\n",
    "        add_circle(np.zeros(shape, dtype=bool), *circle_location1),\n",
    "        add_filled_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
    "        # add_mesh_square(np.zeros(shape, dtype=bool), *mesh_location),\n",
    "        add_plus(np.zeros(shape, dtype=bool), *plus_location)\n",
    "    ]).astype(np.float32)\n",
    "\n",
    "    return arr,masks\n",
    "\n",
    "\n",
    "def add_square(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "    arr[x-s,y-s:y+s] = True\n",
    "    arr[x+s,y-s:y+s] = True\n",
    "    arr[x-s:x+s,y-s] = True\n",
    "    arr[x-s:x+s,y+s] = True\n",
    "\n",
    "    return arr\n",
    "\n",
    "def add_filled_square(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "\n",
    "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
    "\n",
    "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, yy > y - s, yy < y + s]))\n",
    "\n",
    "\n",
    "def logical_and(arrays):\n",
    "    new_array = np.ones(arrays[0].shape, dtype=bool)\n",
    "    for a in arrays:\n",
    "        new_array = np.logical_and(new_array, a)\n",
    "\n",
    "    return new_array\n",
    "\n",
    "\n",
    "def add_mesh_square(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "\n",
    "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
    "\n",
    "    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, xx % 2 == 1, yy > y - s, yy < y + s, yy % 2 == 1]))\n",
    "\n",
    "\n",
    "def add_triangle(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "\n",
    "    triangle = np.tril(np.ones((size, size), dtype=bool))\n",
    "\n",
    "    arr[x-s:x-s+triangle.shape[0],y-s:y-s+triangle.shape[1]] = triangle\n",
    "\n",
    "    return arr\n",
    "\n",
    "def add_circle(arr, x, y, size, fill=False):\n",
    "    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n",
    "    circle = np.sqrt((xx - x) ** 2 + (yy - y) ** 2)\n",
    "    new_arr = np.logical_or(arr, np.logical_and(circle < size, circle >= size * 0.7 if not fill else True))\n",
    "\n",
    "    return new_arr\n",
    "\n",
    "\n",
    "def add_plus(arr, x, y, size):\n",
    "    s = int(size / 2)\n",
    "    arr[x-1:x+1,y-s:y+s] = True\n",
    "    arr[x-s:x+s,y-1:y+1] = True\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_random_location(width,height,zoom=1.0):\n",
    "    x=int(width*random.uniform(0.1,0.9))\n",
    "    y=int(height*random.uniform(0.1,0.9))\n",
    "\n",
    "    size=int(min(width,height)*random.uniform(0.06,.12)*zoom)\n",
    "\n",
    "    return (x,y,size)\n",
    "\n",
    "\n",
    "\n",
    "def plot_img_array(img_array,ncol=3):\n",
    "    nrow=len(img_array) // ncol\n",
    "\n",
    "    f,plots=plt.subplot(nrow,ncol,sharex='all',sharey='all',figsize=(ncol*4,nrow*4))\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        # plots[i//ncol,i%ncol]\n",
    "        plots[i//ncol,i%ncol].imshow(img_array[i])\n",
    "\n",
    "\n",
    "\n",
    "def plot_side_by_side(img_arrays):\n",
    "    flatten_list=reduce(lambda x,y: x*y, zip(*img_arrays))\n",
    "\n",
    "    plot_img_array(np.array(flatten_list),ncol=len(img_arrays))\n",
    "\n",
    "\n",
    "def plot_errors(result_dict,title):\n",
    "\n",
    "    markers=itertools.cycle(('+','x','o'))\n",
    "\n",
    "    plt.title('{}'.format(title))\n",
    "\n",
    "    for label,result in sorted(result_dict.items()):\n",
    "        plt.plot(result,marker=next(markers),label=label)\n",
    "        plt.ylabel('dice_coef')\n",
    "        plt.xlabel('epoch')\n",
    "\n",
    "        plt.legend(loc=3,bbox_to_anchor=(1,0))\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def masks_to_coloring(masks):\n",
    "    colors=np.asarray([(201, 58, 64), (242, 207, 1), (0, 152, 75), (101, 172, 228),(56, 34, 132), (160, 194, 56)])\n",
    "\n",
    "    coloring=np.ones((masks.shape[1],masks.shape[2],3),dtype=np.float32)*255\n",
    "\n",
    "\n",
    "    channels,height,width=masks.shape\n",
    "\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "\n",
    "            selected_colors=colors[masks[:y,x]>0.5]\n",
    "\n",
    "            if len(selected_colors)>0:\n",
    "                coloring[y,x,:]=np.mean(selected_colors,axis=0)\n",
    "\n",
    "    \n",
    "    return coloring.astype(np.uint8)\n",
    "\n",
    "\n",
    "def generate_image_and_masks_then_plot():\n",
    "\n",
    "    # Generate some random images\n",
    "    input_image,target_masks=generate_random_data(192,192,count=3)\n",
    "\n",
    "    for x in [input_image,target_masks]:\n",
    "        print(x.shape)\n",
    "        print(x.min(),x.max())\n",
    "\n",
    "\n",
    "    # Change channel-order and make 3 channels for matplot\n",
    "\n",
    "    input_image_rgb=[x.astype(np.uint8) for x in input_image]\n",
    "\n",
    "    # map each channel (i.e class) to each other \n",
    "    target_mask_rgb=[masks_to_coloring(x) for x in target_masks]\n",
    "\n",
    "    plot_side_by_side([input_image_rgb,target_mask_rgb])\n",
    "\n",
    "\n",
    "\n",
    "def reverse_transform(inp):\n",
    "\n",
    "    inp=inp.numpy().transpose((1,2,0))\n",
    "    mean=np.array([0.485,0.456,0.406])\n",
    "    std=np.array([0.229,0.224,0.225])\n",
    "\n",
    "    inp=std*inp+mean\n",
    "    inp=np.clip(inp,0,1)\n",
    "    inp=(inp*255).astype(np.uint8)\n",
    "\n",
    "    return inp\n",
    "\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self,count,transform=None):\n",
    "        self.input_images,self.target_masks=generate_random_data(192,192,count=count)\n",
    "        self.transform=transform\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image=self.input_images[idx]\n",
    "\n",
    "        mask=self.target_masks[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image=self.transform(image)\n",
    "        \n",
    "        return [image,mask]\n",
    "    \n",
    "\n",
    "def get_data_loaders():\n",
    "    # use the same transformations for train/val in this example\n",
    "\n",
    "    trans=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "\n",
    "    ])\n",
    "\n",
    "    train_set=SimDataset(100,transform=trans)\n",
    "    val_set=SimDataset(20,transform=trans)\n",
    "\n",
    "    # image_dataset={\n",
    "        # 'train':train_set,'val':val_set\n",
    "    # }\n",
    "\n",
    "    batch_size=25\n",
    "\n",
    "    dataloader={\n",
    "        'train':DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=0),\n",
    "        'val':DataLoader(val_set,batch_size=batch_size,shuffle=True,num_workers=0)\n",
    "    }\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "\n",
    "def dice_loss(pred,target,smooth=1.):\n",
    "    pred=pred.contiguous()\n",
    "    target=target.contiguous()\n",
    "\n",
    "    intersection=(pred*target).sum(dim=2).sum(dim=2)\n",
    "\n",
    "    loss=(1-((2.*intersection+smooth)/(pred.sum(dim=2).sum(dim=2)+target.sum(dim=2).sum(dim=2)+smooth)))\n",
    "\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_loss(pred,target,metric,bce_weight=0.5):\n",
    "    \n",
    "    bce=F.binary_cross_entropy_with_logits(pred,target)\n",
    "\n",
    "    pred=F.sigmoid(pred)\n",
    "    dice=dice_loss(pred,target)\n",
    "\n",
    "    loss=bce_weight*bce+(1-bce_weight)*dice\n",
    "\n",
    "    metric['bce']+=bce.data.cpu().numpy()*target.size(0)\n",
    "    metric['dice']+=dice.data.cpu().numpy()*target.size(0)\n",
    "    metric['loss']+=loss.data.cpu().numpy()*target.size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics,epoch_samples,phase):\n",
    "    outputs=[]\n",
    "\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k,metrics[k]/epoch_samples))\n",
    "\n",
    "    print(\"{}:{}\".format(phase,\", \".join(outputs)))\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,optimizer,scheduler,num_epochs=25):\n",
    "    dataloaders=get_data_loaders()\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    best_model_wts=copy.deepcopy(model.state_dict())\n",
    "    best_loss=1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch,num_epochs-1))\n",
    "        print('-'*10)\n",
    "\n",
    "        since=time.time()\n",
    "\n",
    "        for phase in ['train','val']:\n",
    "            if phase=='train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\",param_group['lr'])\n",
    "\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "\n",
    "            epoch_samples=0\n",
    "\n",
    "            for inputs,labels in dataloaders[phase]:\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    outputs=model(inputs)\n",
    "                    loss=calc_loss(outputs,labels,metrics)\n",
    "\n",
    "                     # backward + optimize only if in training phase\n",
    "                    if phase=='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                epoch_samples+=inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics,epoch_samples,phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "def run(UNet):\n",
    "    num_class=6\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model=UNet(num_class).to(device)\n",
    "\n",
    "    optimizer_ft=optim.Adam(filter(lambda p:p.requires_grad,model.parameters()),lr=1e-4)\n",
    "\n",
    "    exp_lr_scheduler=lr_scheduler.StepLR(optimizer_ft,step_size=30,gamma=0.1)\n",
    "\n",
    "    model=train_model(model,optimizer_ft,exp_lr_scheduler,num_epochs=30)\n",
    "\n",
    "    model.eval() # Set model to evaluation mode \n",
    "\n",
    "    trans=transforms.Compose([\n",
    "        transforms.toTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "\n",
    "    ])\n",
    "\n",
    "    # # Create another simulation dataset for test\n",
    "    test_dataset = SimDataset(3, transform = trans)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "    # get the first batch\n",
    "    inputs,labels=next(iter(test_loader))\n",
    "    inputs=inputs.to(device)\n",
    "    labels=labels.to(device)\n",
    "\n",
    "\n",
    "    # Predict\n",
    "\n",
    "    pred=model(inputs)\n",
    "    # the loss function includes the sigmoid function\n",
    "    pred= F.sigmoid(pred)\n",
    "    pred=pred.data.cpu().numpy()\n",
    "    print(pred.shape)\n",
    "\n",
    "    #Change channel-order and make 3 channels for matplot\n",
    "    input_images_rgb=[reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "    # Map each channel (i.e class) to each color \n",
    "    target_masks_rgb=[masks_to_coloring(x) for x in labels.cpu().numpy()]\n",
    "    pred_rgb=[masks_to_coloring(x) for x in pred]\n",
    "\n",
    "    plot_side_by_side([input_images_rgb,target_masks_rgb,pred_rgb])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "LR 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adi_techbuddy/anaconda3/envs/torchenv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/adi_techbuddy/anaconda3/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 978.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608843393/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/adi_techbuddy/anaconda3/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 652.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608843393/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 450.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUNet\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 79\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(UNet)\u001b[0m\n\u001b[1;32m     75\u001b[0m optimizer_ft\u001b[38;5;241m=\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m p:p\u001b[38;5;241m.\u001b[39mrequires_grad,model\u001b[38;5;241m.\u001b[39mparameters()),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     77\u001b[0m exp_lr_scheduler\u001b[38;5;241m=\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_ft,step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m model\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# Set model to evaluation mode \u001b[39;00m\n\u001b[1;32m     83\u001b[0m trans\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     84\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mtoTensor(),\n\u001b[1;32m     85\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize([\u001b[38;5;241m0.485\u001b[39m,\u001b[38;5;241m0.456\u001b[39m,\u001b[38;5;241m0.406\u001b[39m],[\u001b[38;5;241m0.229\u001b[39m,\u001b[38;5;241m0.224\u001b[39m,\u001b[38;5;241m0.225\u001b[39m])\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m ])\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# track history if only in train\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 39\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     loss\u001b[38;5;241m=\u001b[39mcalc_loss(outputs,labels,metrics)\n\u001b[1;32m     42\u001b[0m      \u001b[38;5;66;03m# backward + optimize only if in training phase\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 105\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m xd32 \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md32(xd31))\n\u001b[1;32m    104\u001b[0m xu4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupconv4(xd32)\n\u001b[0;32m--> 105\u001b[0m xu44 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxu4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxe12\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m xd41 \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md41(xu44))\n\u001b[1;32m    107\u001b[0m xd42 \u001b[38;5;241m=\u001b[39m relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md42(xd41))\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 450.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "run(UNet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
