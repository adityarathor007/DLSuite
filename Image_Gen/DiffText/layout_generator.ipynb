{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPTokenizer,CLIPTextModel\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextConditioner(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transformer=CLIPTextModel.from_pretrained('openai/clip-vit-large-patch14')\n",
    "        self.tokenizer=CLIPTokenizer.from_pretrained('openai/clip-vit-large-patch14')\n",
    "\n",
    "        \n",
    "        self.transformer.eval()\n",
    "        for param in self.transformer.parameters():\n",
    "            param.requires_grad=False\n",
    "\n",
    "\n",
    "    def forward(self, prompt_list):\n",
    "        batch_encoding = self.tokenizer(prompt_list, truncation=True, max_length=77, return_length=True, return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        text_embedding = self.transformer(batch_encoding[\"input_ids\"].cuda())\n",
    "        return text_embedding.last_hidden_state.cuda(), batch_encoding[\"attention_mask\"].cuda() # 1, 77, 768  /  1, 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = TextConditioner().cuda().eval()\n",
    "tokenizer = CLIPTokenizer.from_pretrained('openai/clip-vit-large-patch14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_width(font_path, text):\n",
    "    \"\"\"\n",
    "    This function calculates the width of the text.\n",
    "    \n",
    "    Args:\n",
    "        font_path (str): user prompt.\n",
    "        text (str): user prompt.\n",
    "    \"\"\"\n",
    "    font = ImageFont.truetype(font_path, 24)\n",
    "    width = font.getlength(text)\n",
    "    return width\n",
    "\n",
    "def get_key_words(text: str):\n",
    "    \"\"\"\n",
    "    This function detect keywords (enclosed by quotes) from user prompts. The keywords are used to guide the layout generation.\n",
    "    \n",
    "    Args:\n",
    "        text (str): user prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    words = []\n",
    "    text = text\n",
    "    matches = re.findall(r\"'(.*?)'\", text) # find the keywords enclosed by ''\n",
    "    \n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            # words.append(match.split())\n",
    "            words.append(match)\n",
    "            \n",
    "    if len(words) >= 8:\n",
    "        return []\n",
    "    \n",
    "    # print(words)\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_caption(font_path,caption,keywords):\n",
    "    # remove punctuations. please remove this statement if you want to paint punctuations\n",
    "    caption = re.sub(u\"([^\\u0041-\\u005a\\u0061-\\u007a\\u0030-\\u0039])\", \" \", caption) \n",
    "\n",
    "    caption_words=tokenizer([caption],truncation=True, max_length=77, return_length=True, return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    # print(caption_words)\n",
    "\n",
    "    caption_words_ids = caption_words['input_ids'] # (1, 77)  (tokens)\n",
    "    # print(caption_words_ids)\n",
    "    length = caption_words['length'] # (1, )\n",
    "    print(length) #sent_len+2 for sos and eos\n",
    "\n",
    "    # convert id back to words\n",
    "    words = tokenizer.convert_ids_to_tokens(caption_words_ids.view(-1).tolist()) \n",
    "    # print(words)\n",
    "    words = [i.replace('</w>', '') for i in words]\n",
    "    # print(words)\n",
    "    words_valid = words[:int(length)]  #since padding of max_length so after eot tag still eot till 77 will be added\n",
    "    print(words_valid) \n",
    "\n",
    "\n",
    "\n",
    "    # split the caption into words and convert them to lower case\n",
    "    caption_split = caption.split() \n",
    "    caption_split=[i.lower() for i in caption_split]\n",
    "    print(caption_split)\n",
    "\n",
    "    start_dic={}  # get the start index of each word\n",
    "    state_list=[] # 0: start, 1: middle, 2: special token\n",
    "    word_match_list=[]  # the index of the word in the caption\n",
    "    current_caption_index=0\n",
    "    current_match=''\n",
    "\n",
    "    for i in range(length):\n",
    "        \n",
    "        # use first and last token as special tokens\n",
    "        if i==0 or i==length-1:\n",
    "            state_list.append(2) \n",
    "            word_match_list.append(127)\n",
    "            continue\n",
    "            \n",
    "        if current_match=='':\n",
    "            state_list.append(0)\n",
    "            start_dic[current_caption_index]=i\n",
    "\n",
    "        else:\n",
    "            state_list.append(1)\n",
    "\n",
    "        current_match+=words_valid[i]\n",
    "        word_match_list.append(current_caption_index)\n",
    "        if current_match==caption_split[current_caption_index]:\n",
    "            current_match=''\n",
    "            current_caption_index+=1\n",
    "\n",
    "        \n",
    "    \n",
    "    print(state_list) \n",
    "    print(word_match_list)\n",
    "\n",
    "    while len(state_list)<77:\n",
    "        state_list.append(127)\n",
    "    \n",
    "    while len(word_match_list)<77:\n",
    "        word_match_list.append(127)\n",
    "\n",
    "    # print(state_list) \n",
    "    # print(word_match_list)\n",
    "\n",
    "\n",
    "    length_list=[]\n",
    "    width_list=[]\n",
    "\n",
    "    for i in range(len(word_match_list)):\n",
    "        if word_match_list[i]==127:\n",
    "            length_list.append(0)\n",
    "            # width_list.append(0)\n",
    "        else:\n",
    "            length_list.append(len(caption.split()[word_match_list[i]]))  #storing the lenght of the word\n",
    "            width_list.append(get_width(font_path,caption.split()[word_match_list[i]])) #for \n",
    "\n",
    "    \n",
    "    length_list = torch.Tensor(length_list).long() # (77, ) with torch.int64\n",
    "    width_list = torch.Tensor(width_list).long() # (77, )\n",
    "\n",
    "\n",
    "    boxes=[]\n",
    "    duplicate_dict={} #some words may appear more than once\n",
    "    \n",
    "    # store the box coordinates and state of each token\n",
    "    info_array = np.zeros((77,5)) # (77, 5)\n",
    "    \n",
    "\n",
    "    for keyword in keywords:\n",
    "        keyword = keyword.lower()\n",
    "        if keyword in caption_split:\n",
    "            if keyword not in duplicate_dict:\n",
    "                duplicate_dict[keyword] = caption_split.index(keyword) #get the index of the keyword in the sentence\n",
    "                index = caption_split.index(keyword)\n",
    "            else:\n",
    "                if duplicate_dict[keyword]+1 < len(caption_split) and keyword in caption_split[duplicate_dict[keyword]+1:]:\n",
    "                    index = duplicate_dict[keyword] + caption_split[duplicate_dict[keyword]+1:].index(keyword)\n",
    "                    duplicate_dict[keyword] = index\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            index = caption_split.index(keyword) \n",
    "            index = start_dic[index] \n",
    "            info_array[index][0] = 1 #index denote the position of the keyword in the words list\n",
    "\n",
    "            box = [0,0,0,0] \n",
    "            boxes.append(list(box))\n",
    "            info_array[index][1:] = box\n",
    "    \n",
    "    boxes_length=len(boxes)\n",
    "    if boxes_length>8:  #if keywords are more than 8\n",
    "        boxes=boxes[:8]\n",
    "    while len(boxes)<8:\n",
    "        boxes.append([0,0,0,0])\n",
    "\n",
    "\n",
    "    return caption,length_list,width_list,torch.from_numpy(info_array),words,torch.Tensor(state_list).long(),torch.Tensor(word_match_list).long(),torch.Tensor(boxes),boxes_length\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layout_from_prompt():\n",
    "\n",
    "    font_path='/home/adi_techbuddy/Desktop/python/repos/brush-your-text/controlnet_util/Textgen/English/Roboto/static/Roboto-Regular.ttf'\n",
    "    caption=\"I love 'nlp' and 'ai'\"\n",
    "    keywords=get_key_words(caption)\n",
    "    print(\"The following words to be displayed in image were detected\",keywords)\n",
    "\n",
    "    caption,length_list,width_list,target,words,state_list,word_match_list,boxes,boxes_length=process_caption(font_path,caption,keywords)\n",
    "\n",
    "    \n",
    "    print(target.shape)\n",
    "    target=target.cuda().unsqueeze(0)\n",
    "    print(target.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following words to be displayed in image were detected ['nlp', 'ai']\n",
      "tensor([7])\n",
      "['<|startoftext|>', 'i', 'love', 'nlp', 'and', 'ai', '<|endoftext|>']\n",
      "['i', 'love', 'nlp', 'and', 'ai']\n",
      "[2, 0, 0, 0, 0, 0, 2]\n",
      "[127, 0, 1, 2, 3, 4, 127]\n",
      "torch.Size([77, 5])\n",
      "torch.Size([1, 77, 5])\n"
     ]
    }
   ],
   "source": [
    "get_layout_from_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
